{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2e563181",
   "metadata": {},
   "source": [
    "### Runpod 설정"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b8cf8b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "# 모델 저장 경로를 네트워크 볼륨(/workspace) 내부로 지정\n",
    "os.environ[\"HF_HOME\"] = \"/workspace/hf_cache\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5c3c940",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 필수 라이브러리 설치/업데이트\n",
    "!pip install transformers accelerate bitsandbytes openai torch nltk huggingface_hub bert-score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ee683f6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1cae5c05cdc544c2847496e1f75dbba5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(HTML(value='<center> <img\\nsrc=https://huggingface.co/front/assets/huggingface_logo-noborder.sv…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from huggingface_hub import notebook_login\n",
    "notebook_login()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "572b3548",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "386556b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "script = \"상담사: 카드 ▲▲▲입니다.\\n손님: 네, 안녕하세요?\\n상담사: 네, 안녕하세요?\\n손님: 카드 네, 카드 그\\n손님: 돈 빠져 나가는 날짜 있잖아요?\\n상담사: 네.\\n손님: 그것 좀 변경하고 싶은데요\\n상담사: 네, 그러십니까? 카드로 보험료 내시는 날짜 말씀이실까요?\\n손님: 보험료가 아니라 저기 뭐지 어 카드 사용하면\\n상담사: 네,\\n손님: 카드 사용하면 그 지출하는 날짜가 있잖아요?\\n상담사: 아 네 네, 카드 대금 내시는 날짜 결제 일자 말씀 말씀하시는거죠?\\n손님: 네.\\n상담사: 네 네, 그러면 정보 확인 후에 제가 조회 후에 변경 도와드릴 텐데요, 휴대폰 번호와 생년월일 말씀해 주세요.\\n손님: ▲▲▲▲▲▲▲▲▲▲\\n상담사: 네.\\n손님: ▲▲▲▲▲▲\\n상담사: 네, 본인 성함이 어떻게 되십니까? 결제 은행은 어느 은행 이용 중이실까요?\\n손님: ▲▲▲\\n손님: ▲▲\\n상담사: 네, 소중한 정보 확인 감사합니다. 지금은 그러면 ▲▲일부터 말일까지 쓰신 내역을 ▲▲일날 내시는 걸로 되어있는데 그럼 며칠로 변경하시려는 걸까요?\\n손님: 예, 네 네.\\n손님: 아 네, ▲▲일이요.\\n상담사: 네, ▲▲일로 변경하시게 되시면 이제 원래는 ▲▲일부터 말일까지 쓰신 내역을 카드 대금 내셨는데 ▲▲일은 좀 달라요. 매월 월 ▲▲일부터 ▲▲일까지 사용하신 게 ▲▲일 날 청구가 되신다는 점 참고 부탁드리고요. 결제일\\n손님: 네.\\n상담사: 변경하시고 ▲▲▲▲내에는 재변경이 어려울 수 있는데 괜찮으실까요?\\n손님: 네.\\n상담사: 결제일 변경하시고 ▲▲▲내에는 또 다시 변경하시는 게 어려우실 수 있는데 괜찮으실까요? 결제일 변경해도 기존 이용 금액이 변경된 결제일에 청구 되지 않을 수도 있으며 단기 카드 대출이나 자동 이체의 경우 이용 기간에 따라 두 달\\n손님: 아 아 네 네.\\n상담사: 청구되실 수 있다는 점 참고 부탁드리고요, 변경하신 결제일에 대한 이용 기간 한 번 더 문자로 발송해드릴테니 꼭 내용 확인해 보시고 이용 부탁드리겠습니다. 오늘은 ▲▲월부터 지금 변경되신 ▲▲일 날짜에 납부하시게 될 거니 그 부분도 참고 부탁드리겠습니다.\\n손님: 네.\\n상담사: 감사합니다. 완료되셨습니다.\\n손님: 네.\\n상담사: 네, 상담사 ▲▲▲이었습니다.\\n손님: 네.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23674e12",
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt = f\"\"\"\n",
    "상담 스크립트에서 고객(손님)의 발화만을 기준으로 감정을 분석하세요\n",
    "\n",
    "### 분석 규칙\n",
    "1. 상담원 발화는 완전히 무시하고, 고객 발화만 사용합니다\n",
    "2. 전체 상담 스크립트를 시간 흐름 기준으로 3등분하여 감정을 판단합니다\n",
    "3. 각 구간마다 감정을 3가지 중 반드시 하나만 선택합니다 - 부정 | 중립 | 긍정\n",
    "4. 추측, 설명, 해설 문장 금지\n",
    "5. JSON 외의 서론, 결론, 마크다운 기호(```), ```json\\n은 절대 포함하지 마세요\n",
    "\n",
    "### 감정 판단 기준\n",
    "- 부정: 불만, 분노, 짜증, 불안, 항의, 문제 제기\n",
    "- 중립: 사실 전달, 질문, 감정 표현 거의 없음\n",
    "- 긍정: 만족, 안도, 감사, 동의, 긍정적 반응\n",
    "\n",
    "### 상담 스크립트\n",
    "{script}\n",
    "\n",
    "### 출력 형식(JSON 고정)\n",
    "{{\n",
    "  \"early\": \"부정|중립|긍정\",\n",
    "  \"mid\": \"부정|중립|긍정\",\n",
    "  \"late\": \"부정|중립|긍정\"\n",
    "}}\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "02c1c36f",
   "metadata": {},
   "source": [
    "---\n",
    "### GPT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "200e79ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "import json\n",
    "import openai"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "2ebedbfa",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_feedback_openai(model_name, prompt):\n",
    "    start_time = time.perf_counter()\n",
    "    ttft = 0\n",
    "    generated_tokens = 0\n",
    "    content = \"\"\n",
    "    first_token_received = False\n",
    "    \n",
    "    try:\n",
    "        response = openai.chat.completions.create(\n",
    "            model=model_name,\n",
    "            messages=[{\"role\": \"user\", \"content\": prompt}],\n",
    "            temperature=0,\n",
    "            response_format={\"type\": \"json_object\"},\n",
    "            stream=True,                              # 토큰 단위로 수신\n",
    "            stream_options={\"include_usage\": True}    # 마지막 chunk에 토큰 정보 포함\n",
    "        )\n",
    "        \n",
    "        for chunk in response:\n",
    "            # 첫번째 토큰이 들어오는 시점 확인 (ttft)\n",
    "            if not first_token_received and chunk.choices and chunk.choices[0].delta.content:\n",
    "                ttft = time.perf_counter() - start_time\n",
    "                first_token_received = True\n",
    "            \n",
    "            # 내용 누적\n",
    "            if chunk.choices and chunk.choices[0].delta.content:\n",
    "                content += chunk.choices[0].delta.content\n",
    "            \n",
    "            # 토큰 사용량 확인\n",
    "            if chunk.usage is not None:\n",
    "                generated_tokens = chunk.usage.completion_tokens\n",
    "        \n",
    "        end_time = time.perf_counter()\n",
    "        total_duration = end_time - start_time\n",
    "        \n",
    "        # tps 계산 (생성된 토큰 수 / 전체 소요 시간)\n",
    "        tps = generated_tokens / total_duration if total_duration > 0 else 0\n",
    "\n",
    "        result_json = json.loads(content)\n",
    "        \n",
    "        metrics = {\n",
    "                \"ttft\": round(ttft, 3),\n",
    "                \"tps\": round(tps, 2),\n",
    "                \"total_tokens\": generated_tokens\n",
    "            }\n",
    "\n",
    "        return result_json, metrics\n",
    "    except Exception as e:\n",
    "        return f\"{model_name} 호출 중 오류 발생 : {e}\", \"오류\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "1150707f",
   "metadata": {},
   "outputs": [],
   "source": [
    "res_gpt_sm, metrics_gpt_sm = generate_feedback_openai(\"gpt-4.1-mini\", prompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "476fff07",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'초반': '중립', '중반': '중립', '후반': '긍정'}"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "res_gpt_sm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "e3c14885",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'ttft': 0.406, 'tps': 37.2, 'total_tokens': 30}"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "metrics_gpt_sm"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a2e2d872",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f9925906",
   "metadata": {},
   "source": [
    "### sllm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0e63f86",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import json\n",
    "import time\n",
    "import torch\n",
    "from transformers import AutoModelForCausalLM, AutoTokenizer, TextIteratorStreamer\n",
    "from threading import Thread"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5325112b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_summary_sllm(model_name, prompt):\n",
    "    try:\n",
    "        # 모델 및 토크나이저 로드\n",
    "        tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "        model = AutoModelForCausalLM.from_pretrained(\n",
    "            model_name,\n",
    "            torch_dtype=torch.bfloat16,\n",
    "            device_map=\"auto\",\n",
    "            trust_remote_code=True\n",
    "        )\n",
    "        \n",
    "        if tokenizer.pad_token is None:\n",
    "            tokenizer.pad_token = tokenizer.eos_token\n",
    "        \n",
    "        messages = [{\"role\": \"system\", \"content\": prompt}]\n",
    "        inputs = tokenizer.apply_chat_template(\n",
    "            messages, \n",
    "            tokenize=True, \n",
    "            add_generation_prompt=True, \n",
    "            return_tensors=\"pt\"\n",
    "        ).to(model.device)\n",
    "\n",
    "        # 스트리머 설정\n",
    "        streamer = TextIteratorStreamer(tokenizer, skip_prompt=True, skip_special_tokens=True)\n",
    "        \n",
    "        # 측정 변수 초기화\n",
    "        start_time = time.perf_counter()\n",
    "        ttft = 0\n",
    "        first_token_received = False\n",
    "        full_content = \"\"\n",
    "        generated_token_count = 0\n",
    "\n",
    "        # 생성 프로세스를 별도 스레드에서 실행\n",
    "        generation_kwargs = dict(\n",
    "            input_ids=inputs,\n",
    "            streamer=streamer,\n",
    "            max_new_tokens=512,\n",
    "            repetition_penalty=1.2,\n",
    "            do_sample=False,\n",
    "            temperature=0.1,\n",
    "            eos_token_id=tokenizer.eos_token_id,\n",
    "            pad_token_id=tokenizer.pad_token_id\n",
    "        )\n",
    "        \n",
    "        thread = Thread(target=model.generate, kwargs=generation_kwargs)\n",
    "        thread.start()\n",
    "\n",
    "        # 토큰을 하나씩 읽으며 ttft 측정\n",
    "        for new_text in streamer:\n",
    "            if not first_token_received and len(new_text) > 0:\n",
    "                ttft = time.perf_counter() - start_time\n",
    "                first_token_received = True\n",
    "            \n",
    "            full_content += new_text\n",
    "\n",
    "        thread.join()\n",
    "        end_time = time.perf_counter()\n",
    "        \n",
    "        total_duration = end_time - start_time\n",
    "        generated_token_count = len(tokenizer.encode(full_content))\n",
    "        tps = generated_token_count / total_duration if total_duration > 0 else 0\n",
    "\n",
    "        # JSON 추출 및 파싱\n",
    "        try:\n",
    "            json_match = re.search(r'(\\{.*\\})', full_content, re.DOTALL)\n",
    "            if json_match:\n",
    "                content = json.loads(json_match.group(1))\n",
    "            else:\n",
    "                content = {\"error\": \"JSON 형식을 찾을 수 없음\", \"raw\": full_content}\n",
    "        except json.JSONDecodeError:\n",
    "            content = {\"error\": \"JSON 파싱 실패\", \"raw\": full_content}\n",
    "\n",
    "        # 리소스 정리\n",
    "        del model, tokenizer, inputs\n",
    "        torch.cuda.empty_cache()\n",
    "\n",
    "        metrics = {\n",
    "            \"ttft\": round(ttft, 3),\n",
    "            \"tps\": round(tps, 2),\n",
    "            \"total_tokens\": generated_token_count\n",
    "        }\n",
    "\n",
    "        return content, metrics\n",
    "\n",
    "    except Exception as e:\n",
    "        return f\"{model_name} 호출 중 오류 발생 : {e}\", None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0214b2ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "res, metrics = generate_summary_sllm(\"kakaocorp/kanana-nano-2.1b-instruct\", prompt)\n",
    "# res, metrics = generate_summary_sllm(\"kakaocorp/kanana-1.5-8b-instruct-2505\", prompt)\n",
    "# res, metrics = generate_summary_sllm(\"LGAI-EXAONE/EXAONE-3.5-2.4B-Instruct\", prompt)\n",
    "# res, metrics = generate_summary_sllm(\"LGAI-EXAONE/EXAONE-3.5-7.8B-Instruct\", prompt)\n",
    "# res, metrics = generate_summary_sllm(\"naver-hyperclovax/HyperCLOVAX-SEED-Text-Instruct-1.5B\", prompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fced2a15",
   "metadata": {},
   "outputs": [],
   "source": [
    "res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "273a8fb7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "테스트 실행 중: 20593\n",
      "테스트 실행 중: 20594\n",
      "테스트 실행 중: 20596\n",
      "테스트 실행 중: 20597\n",
      "테스트 실행 중: 20598\n",
      "테스트 실행 중: 20599\n",
      "테스트 실행 중: 20600\n",
      "테스트 실행 중: 20601\n",
      "테스트 실행 중: 20602\n",
      "테스트 실행 중: 20603\n",
      "테스트 실행 중: 20604\n",
      "테스트 실행 중: 20605\n",
      "테스트 실행 중: 20606\n",
      "테스트 실행 중: 20607\n",
      "테스트 실행 중: 20608\n",
      "테스트 실행 중: 20609\n",
      "테스트 실행 중: 20610\n",
      "테스트 실행 중: 20611\n",
      "테스트 실행 중: 20612\n",
      "테스트 실행 중: 20613\n",
      "테스트 실행 중: 20614\n",
      "테스트 실행 중: 20615\n",
      "테스트 실행 중: 20616\n",
      "테스트 실행 중: 20617\n",
      "테스트 실행 중: 20618\n",
      "테스트 실행 중: 20619\n",
      "테스트 실행 중: 20620\n",
      "테스트 실행 중: 20621\n",
      "테스트 실행 중: 20622\n",
      "테스트 실행 중: 20623\n",
      "테스트 실행 중: 20624\n",
      "테스트 실행 중: 20625\n",
      "테스트 실행 중: 20626\n",
      "테스트 실행 중: 20627\n",
      "테스트 실행 중: 20628\n",
      "테스트 실행 중: 20629\n",
      "테스트 실행 중: 20630\n",
      "테스트 실행 중: 20631\n",
      "테스트 실행 중: 20632\n",
      "테스트 실행 중: 20633\n",
      "테스트 실행 중: 20634\n",
      "테스트 실행 중: 20635\n",
      "테스트 실행 중: 20636\n",
      "테스트 실행 중: 20637\n",
      "테스트 실행 중: 20638\n",
      "테스트 실행 중: 20639\n",
      "테스트 실행 중: 20640\n",
      "테스트 실행 중: 20641\n",
      "테스트 실행 중: 20642\n",
      "테스트 실행 중: 20643\n",
      "테스트 실행 중: 20644\n",
      "테스트 실행 중: 20645\n",
      "테스트 실행 중: 20646\n",
      "테스트 실행 중: 20647\n",
      "테스트 실행 중: 20648\n",
      "테스트 실행 중: 20649\n",
      "테스트 실행 중: 20650\n",
      "테스트 실행 중: 20651\n",
      "테스트 실행 중: 20652\n",
      "테스트 실행 중: 20653\n",
      "테스트 실행 중: 20654\n",
      "테스트 실행 중: 20655\n",
      "테스트 실행 중: 20656\n",
      "테스트 실행 중: 20657\n",
      "테스트 실행 중: 20658\n",
      "테스트 실행 중: 20659\n",
      "테스트 실행 중: 20660\n",
      "테스트 실행 중: 20661\n",
      "테스트 실행 중: 20662\n",
      "테스트 실행 중: 20663\n",
      "테스트 실행 중: 20664\n",
      "테스트 실행 중: 20665\n",
      "테스트 실행 중: 20666\n",
      "테스트 실행 중: 20667\n",
      "테스트 실행 중: 20668\n",
      "테스트 실행 중: 20669\n",
      "테스트 실행 중: 20670\n",
      "테스트 실행 중: 20671\n",
      "테스트 실행 중: 20672\n",
      "테스트 실행 중: 20673\n",
      "테스트 실행 중: 20674\n",
      "테스트 실행 중: 20675\n",
      "테스트 실행 중: 20676\n",
      "테스트 실행 중: 20677\n",
      "테스트 실행 중: 20678\n",
      "테스트 실행 중: 20679\n",
      "테스트 실행 중: 20680\n",
      "테스트 실행 중: 20681\n",
      "테스트 실행 중: 20682\n",
      "테스트 실행 중: 20683\n",
      "테스트 실행 중: 20684\n",
      "테스트 실행 중: 20685\n",
      "테스트 실행 중: 20686\n",
      "테스트 실행 중: 20687\n",
      "테스트 실행 중: 20688\n",
      "테스트 실행 중: 20689\n",
      "테스트 실행 중: 20690\n",
      "테스트 실행 중: 20691\n",
      "테스트 실행 중: 20692\n",
      "테스트 실행 중: 20693\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import json\n",
    "import glob\n",
    "\n",
    "# 파일 경로 설정\n",
    "testset_dir = \"./testsets\"\n",
    "json_files = glob.glob(os.path.join(testset_dir, \"*.json\"))\n",
    "\n",
    "results_list = []\n",
    "\n",
    "# 파일 루프 시작\n",
    "for file_path in json_files:\n",
    "    with open(file_path, 'r', encoding='utf-8') as f:\n",
    "        data_list = json.load(f)\n",
    "        \n",
    "    for item in data_list:\n",
    "        # 데이터 추출\n",
    "        script = item.get('consulting_content', \"\")\n",
    "        summary_ref = item['instructions'][0]['data'][0]['output']\n",
    "\n",
    "        print(f\"테스트 실행 중: {item.get('source_id', 'Unknown ID')}\")\n",
    "\n",
    "        # 모델 테스트\n",
    "        # prompt 생성\n",
    "        system_prompt = f\"\"\"\n",
    "        상담 스크립트를 평가 기준에 따라 객관적으로 평가하세요\n",
    "\n",
    "        ### 제약 사항\n",
    "        1. 모든 감점에는 구체적인 발화 근거를 반드시 제시한다\n",
    "        2. 고객의 감사 표현은 고객 발화에서만 카운트한다\n",
    "        3. 추측, 설명 문장, 자연어 해설 금지 - JSON만 출력한다\n",
    "        4. 총 점수는 60점이며 각 2개 점수의 총합이다\n",
    "\n",
    "        ### 상담 스크립트\n",
    "        {script}\n",
    "\n",
    "        ### 평가 기준\n",
    "        1. 매뉴얼 준수 (50점에서 감점하는 방식)\n",
    "        intro\n",
    "        - 인사말\n",
    "        0점: 첫인사 + 마무리 멘트 모두 수행\n",
    "        -5점: 첫인사 또는 마무리 멘트 누락\n",
    "        - 고객확인\n",
    "        0점: 고객정보를 고객에게 직접 질문\n",
    "        -5점: 상담원이 고객정보를 먼저 발화하여 정보 누출\n",
    "\n",
    "        response\n",
    "        - 호응어\n",
    "        0점: 공감/감성 호응\n",
    "        -5점: 기운 없음, 짜증 섞인 표현\n",
    "        - 대기 표현\n",
    "        0점: 대기 표현 모두 수행\n",
    "        -5점: 대기 표현 누락\n",
    "\n",
    "        explanation\n",
    "        - 커뮤니케이션\n",
    "        0점: 핵심 요약 + 이해 쉬운 설명\n",
    "        -5점: 일방적 설명, 단답형\n",
    "        - 알기 쉬운 설명\n",
    "        0점: 고객 눈높이 설명 + 부연\n",
    "        -5점: 복잡한 설명/상담자 관점 설명\n",
    "\n",
    "        proactivity\n",
    "        - 적극성\n",
    "        0점: 적극적 대응\n",
    "        -5점: 수동적 대응, 대안 없음\n",
    "        - 언어표현\n",
    "        0점: 정중/경어체/긍정 표현\n",
    "        -5점: 전문용어, 줄임말, 명령조, 무시 표현\n",
    "\n",
    "        accuracy\n",
    "        - 정확한 업무처리\n",
    "        0점: 오류 없음\n",
    "        -10점: 임의 판단으로 업무 오류 발생\n",
    "\n",
    "        2. 고객 감사 표현 (10점)\n",
    "        - 고객 발화 중 감사/칭찬 키워드 포함 시 1회 카운트\n",
    "        - 0회: 0점 / 1회: 5점 / 2회 이상: 10점\n",
    "\n",
    "\n",
    "        ### 출력 형식 (JSON)\n",
    "        {{\n",
    "        \"manual_compliance\": {{\n",
    "            \"intro\": {{\n",
    "            \"score\": 0,\n",
    "            \"evidence\": []\n",
    "            }},\n",
    "            \"response\": {{\n",
    "            \"score\": 0,\n",
    "            \"evidence\": []\n",
    "            }},\n",
    "            \"explanation\": {{\n",
    "            \"score\": 0,\n",
    "            \"evidence\": []\n",
    "            }},\n",
    "            \"proactivity\": {{\n",
    "            \"score\": 0,\n",
    "            \"evidence\": []\n",
    "            }},\n",
    "            \"accuracy\": {{\n",
    "            \"score\": 0,\n",
    "            \"evidence\": []\n",
    "            }},\n",
    "            \"manual_score\": \"0~50점\"\n",
    "        }},\n",
    "        \"customer_thanks\": {{\n",
    "            \"count\": 0,\n",
    "            \"thanks_score\": \"0~10점\",\n",
    "            \"evidence\": []\n",
    "        }},\n",
    "        \"final_score\": {{\n",
    "            \"total\": \"manual_score + thanks_score\",\n",
    "            \"feedback\": \"\"\n",
    "        }}\n",
    "        }}\n",
    "        \"\"\"\n",
    "        \n",
    "        res, metrics = generate_summary_sllm(\"kakaocorp/kanana-nano-2.1b-instruct\", system_prompt)\n",
    "        # res, metrics = generate_summary_sllm(\"kakaocorp/kanana-1.5-8b-instruct-2505\", system_prompt)\n",
    "        # res, metrics = generate_summary_sllm(\"LGAI-EXAONE/EXAONE-3.5-2.4B-Instruct\", system_prompt)\n",
    "        # res, metrics = generate_summary_sllm(\"LGAI-EXAONE/EXAONE-3.5-7.8B-Instruct\", system_prompt)\n",
    "        # res, metrics = generate_summary_sllm(\"naver-hyperclovax/HyperCLOVAX-SEED-Text-Instruct-1.5B\", system_prompt)\n",
    "        # res, metrics = generate_feedback_openai(\"gpt-4.1-mini\", system_prompt)\n",
    "            \n",
    "        # 결과 저장\n",
    "        results_list.append({\n",
    "            \"id\": item.get('source_id'),\n",
    "            \"res\": res,\n",
    "            \"metrics\": metrics,\n",
    "        })"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d3b0d3a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "데이터가 추가되었습니다: evaluation_results_feedback.csv\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "\n",
    "df_new = pd.json_normalize(results_list)\n",
    "df_new['model'] = \"kanana-nano-2.1b\" \n",
    "\n",
    "output_file = \"evaluation_results_feedback.csv\"\n",
    "\n",
    "if not os.path.exists(output_file):\n",
    "    df_new.to_csv(output_file, index=False, mode='w', encoding='utf-8-sig')\n",
    "else:\n",
    "    df_new.to_csv(output_file, index=False, mode='a', encoding='utf-8-sig', header=False)\n",
    "\n",
    "print(f\"데이터가 추가되었습니다: {output_file}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "final_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
