{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "93aa7b35",
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "import pandas as pd\n",
    "from difflib import SequenceMatcher\n",
    "from llama_cpp import Llama"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "bceeb3aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "MODEL_PATH = \"./models/EXAONE-3.5-2.4B-Instruct-Q4_K_M.gguf\"\n",
    "\n",
    "TEST_DATASET = [\n",
    "    {\"input\": \"ì¹´ë“œ ê°‘ì”¨ ì™œ ì´ë ‡ê²Œ ë§ì´ ë‚˜ì™”ì–´ìš”\", \"truth\": \"ì¹´ë“œ ê°’ì´ ì™œ ì´ë ‡ê²Œ ë§ì´ ë‚˜ì™”ì–´ìš”\"},\n",
    "    {\"input\": \"ë¦¬ë²Œë¹™ ì‹ ì²­ í•­ê±° ì·¨ì†Œí• ë ¤êµ¬ìš”\", \"truth\": \"ë¦¬ë³¼ë¹™ ì‹ ì²­í•œ ê±° ì·¨ì†Œí•˜ë ¤ê³ ìš”\"},\n",
    "    {\"input\": \"ì´ë²ˆë”¸ ê±€ì œì¼ì´ ì–¸ì œì—¬\", \"truth\": \"ì´ë²ˆ ë‹¬ ê²°ì œì¼ì´ ì–¸ì œì˜ˆìš”\"},\n",
    "    {\"input\": \"í•œë‘ ìƒì–‘ ì¢€ ë¶€íƒë“œë ¤ì—¬\", \"truth\": \"í•œë„ ìƒí–¥ ì¢€ ë¶€íƒë“œë ¤ìš”\"},\n",
    "    {\"input\": \"ì¼ì”¨ë¶ˆë¡œ ê¸ì—ˆëŠ”ë° í• ë¶€ë¡œ ë°”ê¿€ìˆ˜ ì´ì¨ìš”?\", \"truth\": \"ì¼ì‹œë¶ˆë¡œ ê¸ì—ˆëŠ”ë° í• ë¶€ë¡œ ë°”ê¿€ ìˆ˜ ìˆì–´ìš”?\"},\n",
    "    {\"input\": \"ì±„í¬ì¹´ë“œ ì¬ë°œê¸‰ ë°”ë“¤ë ¤êµ¬ìš”\", \"truth\": \"ì²´í¬ì¹´ë“œ ì¬ë°œê¸‰ ë°›ìœ¼ë ¤ê³ ìš”\"},\n",
    "    {\"input\": \"ì•„ë‹ˆ ê·¸ ë¨¸ëƒ ê²°ì œ ì·¨ì†Œê°€ ì•ˆëŒ€ìë‚˜ìš”\", \"truth\": \"ê²°ì œ ì·¨ì†Œê°€ ì•ˆ ë˜ì–ì•„ìš”\"},\n",
    "    {\"input\": \"í•´ì™¸ê²¨ì œ ì°¨ë‹¨ í‘¸ëŸ¬ì£¼ì„¸ìš”\", \"truth\": \"í•´ì™¸ê²°ì œ ì°¨ë‹¨ í’€ì–´ì£¼ì„¸ìš”\"}\n",
    "]\n",
    "\n",
    "SYSTEM_PROMPT = \"\"\"\n",
    "ë‹¹ì‹ ì€ ê¸ˆìœµê¶Œ íšŒì‚¬ì˜ ë§ì¶¤ë²• êµì • ì „ë¬¸ê°€ì…ë‹ˆë‹¤.\n",
    "ì‚¬ìš©ìê°€ ì…ë ¥í•˜ëŠ” ë¬¸ì¥ì€ ë°œìŒ ì˜¤ë¥˜, ì˜¤íƒ€, ë„ì–´ì“°ê¸° ì˜¤ë¥˜ê°€ í¬í•¨ëœ í…ìŠ¤íŠ¸ì…ë‹ˆë‹¤.\n",
    "\n",
    "[ì§€ì‹œì‚¬í•­]\n",
    "0. ì…ë ¥ëœ ì§ˆë¬¸ì— ëŒ€í•´ ë‹µë³€í•˜ì§€ ë§ê³ , í•´ë‹¹ ë¬¸ì¥ì˜ ë¬¸ë²•ì„ êµì •í•˜ì‹­ì‹œì˜¤.\n",
    "1. ì…ë ¥ëœ ë¬¸ì¥ì˜ ì˜ë¯¸ë¥¼ íŒŒì•…í•˜ì—¬ ì •í™•í•œ ë¬¸ë²•ê³¼ ì¹´ë“œì‚¬ ì „ë¬¸ ìš©ì–´ë¡œ êµì •í•˜ì‹­ì‹œì˜¤.\n",
    "2. ë¶ˆí•„ìš”í•œ ì¶”ì„ìƒˆ(ìŒ, ê·¸, ë¨¸ëƒ ë“±)ëŠ” ì œê±°í•˜ì‹­ì‹œì˜¤.\n",
    "3. ìˆ«ìëŠ” ê°€ê¸‰ì  ì•„ë¼ë¹„ì•„ ìˆ«ì(ì˜ˆ: 3ê°œì›”)ë¡œ í‘œê¸°í•˜ì‹­ì‹œì˜¤.\n",
    "4. ì ˆëŒ€ ë¶€ê°€ì ì¸ ì„¤ëª…ì´ë‚˜ ì¸ì‚¬ë¥¼ í•˜ì§€ ë§ˆì‹­ì‹œì˜¤. ì˜¤ì§ 'êµì •ëœ í…ìŠ¤íŠ¸'ë§Œ ì¶œë ¥í•˜ì‹­ì‹œì˜¤.\n",
    "\n",
    "[ì˜ˆì‹œ]\n",
    "ì…ë ¥: ì¹´ë“œ ê°‘ì”¨ ì™œ ì´ë ‡ê²Œ ë§ì´ ë‚˜ì™”ì–´ìš”\n",
    "êµì •: ì¹´ë“œ ê°’ì´ ì™œ ì´ë ‡ê²Œ ë§ì´ ë‚˜ì™”ì–´ìš”\n",
    "\n",
    "ì…ë ¥: ë¦¬ë²Œë¹™ ì‹ ì²­ í•­ê±° ì·¨ì†Œí• ë ¤êµ¬ìš”\n",
    "êµì •: ë¦¬ë³¼ë¹™ ì‹ ì²­í•œ ê±° ì·¨ì†Œí•˜ë ¤ê³ ìš”\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59d09853",
   "metadata": {},
   "outputs": [],
   "source": [
    "class STTFilterEvaluator:\n",
    "    def __init__(self, model_path):\n",
    "        print(f\"ğŸ”„ Loading Correction Model...\")\n",
    "        try:\n",
    "            self.llm = Llama(\n",
    "                model_path=model_path,\n",
    "                n_gpu_layers=-1,\n",
    "                n_ctx=2048,\n",
    "                verbose=False\n",
    "            )\n",
    "            print(\"âœ… Model Loaded.\")\n",
    "        except Exception as e:\n",
    "            print(f\"âŒ Load Failed: {e}\")\n",
    "            self.llm = None\n",
    "\n",
    "    def correct_text(self, noisy_text):\n",
    "        if not self.llm: return \"Error\"\n",
    "        \n",
    "        try:\n",
    "            messages = [\n",
    "                {\"role\": \"system\", \"content\": SYSTEM_PROMPT},\n",
    "                {\"role\": \"user\", \"content\": f\"ì…ë ¥: {noisy_text}\"}\n",
    "            ]\n",
    "            \n",
    "            output = self.llm.create_chat_completion(\n",
    "                messages=messages,\n",
    "                max_tokens=128,     # êµì • í…ìŠ¤íŠ¸ëŠ” ê¸¸ì§€ ì•Šìœ¼ë¯€ë¡œ ì§§ê²Œ ì œí•œ\n",
    "                temperature=0.1     # ì°½ì˜ì„± ì–µì œ (ì •í™•ë„ ìš°ì„ )\n",
    "            )\n",
    "            return output['choices'][0]['message']['content'].strip()\n",
    "        except ValueError:\n",
    "             # System role ë¯¸ì§€ì› ëª¨ë¸(Gemma ë“±) Fallback\n",
    "            prompt = f\"{SYSTEM_PROMPT}\\n\\nì…ë ¥: {noisy_text}\\nêµì • ê²°ê³¼:\"\n",
    "            output = self.llm.create_completion(\n",
    "                prompt=prompt, max_tokens=128, temperature=0.1\n",
    "            )\n",
    "            return output['choices'][0]['text'].strip()\n",
    "\n",
    "    def calculate_similarity(self, a, b):\n",
    "        return SequenceMatcher(None, a, b).ratio()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d38ef61b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def main():\n",
    "    evaluator = STTFilterEvaluator(MODEL_PATH)\n",
    "    if not evaluator.llm: return\n",
    "\n",
    "    results = []\n",
    "\n",
    "    for idx, data in enumerate(TEST_DATASET):\n",
    "        noisy_input = data['input']\n",
    "        ground_truth = data['truth']\n",
    "\n",
    "        start_time = time.time()\n",
    "        corrected_output = evaluator.correct_text(noisy_input)\n",
    "        elapsed = time.time() - start_time\n",
    "\n",
    "        # ìœ ì‚¬ë„ ì ìˆ˜ (100ì  ë§Œì )\n",
    "        score = evaluator.calculate_similarity(ground_truth, corrected_output) * 100\n",
    "\n",
    "        print(f\"Input: {noisy_input}\")\n",
    "        print(f\"Pred : {corrected_output}\")\n",
    "        print(f\"Truth: {ground_truth}\")\n",
    "        print(f\"Score: {score:.1f} / Time: {elapsed:.2f}s\\n\")\n",
    "\n",
    "        results.append({\n",
    "            \"Noisy Input\": noisy_input,\n",
    "            \"Model Output\": corrected_output,\n",
    "            \"Ground Truth\": ground_truth,\n",
    "            \"Similarity\": round(score, 1),\n",
    "            \"Time(s)\": round(elapsed, 3)\n",
    "        })\n",
    "\n",
    "    # ê²°ê³¼ ì €ì¥\n",
    "    df = pd.DataFrame(results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "69fc2450",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸ”„ Loading Correction Model...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "llama_context: n_ctx_per_seq (2048) < n_ctx_train (32768) -- the full capacity of the model will not be utilized\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… Model Loaded.\n",
      "\n",
      "ğŸš€ [STT Correction Test Started]\n",
      "\n",
      "Input: ì¹´ë“œ ê°‘ì”¨ ì™œ ì´ë ‡ê²Œ ë§ì´ ë‚˜ì™”ì–´ìš”\n",
      "Pred : êµì •: ì¹´ë“œ ì´ìš©ê¸ˆì•¡ì´ ì™œ ì´ë ‡ê²Œ ë§ì´ ë‚˜ì™”ë‚˜ìš”?\n",
      "Truth: ì¹´ë“œ ê°’ì´ ì™œ ì´ë ‡ê²Œ ë§ì´ ë‚˜ì™”ì–´ìš”\n",
      "Score: 73.9 / Time: 2.99s\n",
      "\n",
      "Input: ë¦¬ë²Œë¹™ ì‹ ì²­ í•­ê±° ì·¨ì†Œí• ë ¤êµ¬ìš”\n",
      "Pred : ë¦¬ë³¼ë¹™ ì‹ ì²­ì„ ì·¨ì†Œí•˜ë ¤ê³  í•©ë‹ˆë‹¤.\n",
      "Truth: ë¦¬ë³¼ë¹™ ì‹ ì²­í•œ ê±° ì·¨ì†Œí•˜ë ¤ê³ ìš”\n",
      "Score: 70.6 / Time: 0.72s\n",
      "\n",
      "Input: ì´ë²ˆë”¸ ê±€ì œì¼ì´ ì–¸ì œì—¬\n",
      "Pred : êµì •: ì´ë²ˆ ì²´í¬ì¼ì´ ì–¸ì œì¸ê°€ìš”?\n",
      "Truth: ì´ë²ˆ ë‹¬ ê²°ì œì¼ì´ ì–¸ì œì˜ˆìš”\n",
      "Score: 56.2 / Time: 0.74s\n",
      "\n",
      "Input: í•œë‘ ìƒì–‘ ì¢€ ë¶€íƒë“œë ¤ì—¬\n",
      "Pred : ì…ë ¥: í•œë‘ ìƒëŸ‰ ì¢€ ë¶€íƒë“œë¦¬ê² ìŠµë‹ˆë‹¤.\n",
      "Truth: í•œë„ ìƒí–¥ ì¢€ ë¶€íƒë“œë ¤ìš”\n",
      "Score: 52.9 / Time: 0.77s\n",
      "\n",
      "Input: ì¼ì”¨ë¶ˆë¡œ ê¸ì—ˆëŠ”ë° í• ë¶€ë¡œ ë°”ê¿€ìˆ˜ ì´ì¨ìš”?\n",
      "Pred : ì…ë ¥: ì¼ì”¨ë¶ˆë¡œ ê¸ì—ˆëŠ”ë° í• ë¶€ë¡œ ë°”ê¿€ ìˆ˜ ìˆë‚˜ìš”?\n",
      "Truth: ì¼ì‹œë¶ˆë¡œ ê¸ì—ˆëŠ”ë° í• ë¶€ë¡œ ë°”ê¿€ ìˆ˜ ìˆì–´ìš”?\n",
      "Score: 84.0 / Time: 1.09s\n",
      "\n",
      "Input: ì±„í¬ì¹´ë“œ ì¬ë°œê¸‰ ë°”ë“¤ë ¤êµ¬ìš”\n",
      "Pred : êµì •: ì²´í¬ì¹´ë“œ ì¬ë°œê¸‰ ìš”ì²­ë“œë¦½ë‹ˆë‹¤.\n",
      "Truth: ì²´í¬ì¹´ë“œ ì¬ë°œê¸‰ ë°›ìœ¼ë ¤ê³ ìš”\n",
      "Score: 58.8 / Time: 0.72s\n",
      "\n",
      "Input: ì•„ë‹ˆ ê·¸ ë¨¸ëƒ ê²°ì œ ì·¨ì†Œê°€ ì•ˆëŒ€ìë‚˜ìš”\n",
      "Pred : ì•„ë‹ˆìš”, ê²°ì œ ì·¨ì†Œê°€ ë¶ˆê°€ëŠ¥í•˜ì§€ ì•Šë‚˜ìš”?\n",
      "Truth: ê²°ì œ ì·¨ì†Œê°€ ì•ˆ ë˜ì–ì•„ìš”\n",
      "Score: 51.4 / Time: 0.88s\n",
      "\n",
      "Input: í•´ì™¸ê²¨ì œ ì°¨ë‹¨ í‘¸ëŸ¬ì£¼ì„¸ìš”\n",
      "Pred : ì…ë ¥: í•´ì™¸ê±°ë˜ ì°¨ë‹¨ í•´ì œ ë¶€íƒë“œë¦½ë‹ˆë‹¤.\n",
      "Truth: í•´ì™¸ê²°ì œ ì°¨ë‹¨ í’€ì–´ì£¼ì„¸ìš”\n",
      "Score: 34.3 / Time: 0.62s\n",
      "\n"
     ]
    }
   ],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "final_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
