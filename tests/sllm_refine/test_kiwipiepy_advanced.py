"""
Kiwipiepy ê³ ê¸‰ ê¸°ëŠ¥ í…ŒìŠ¤íŠ¸

í…ŒìŠ¤íŠ¸ í•­ëª©:
1. ì˜¤íƒ€ êµì • ê¸°ëŠ¥
2. ê¸°ë¶„ì„ í˜•íƒœ ë“±ë¡
3. í†µí•© íŒŒì´í”„ë¼ì¸
"""

import sys
from pathlib import Path

sys.path.insert(0, str(Path(__file__).resolve().parent.parent.parent))

from app.llm.delivery.morphology_analyzer import (
    analyze_morphemes,
    extract_nouns,
    get_kiwi
)


def test_typo_correction():
    """ì˜¤íƒ€ êµì • ê¸°ëŠ¥ í…ŒìŠ¤íŠ¸"""
    print("=" * 70)
    print("ì˜¤íƒ€ êµì • ê¸°ëŠ¥ í…ŒìŠ¤íŠ¸")
    print("=" * 70)
    
    test_cases = [
        ("í•˜ë‚˜ë‚¸ ê³„ì¢Œì—ì„œ", ["í•˜ë‚˜ì€í–‰", "ê³„ì¢Œ"]),
        ("ì—°ì˜ˆë¹„ ë‚©ë¶€", ["ì—°íšŒë¹„", "ë‚©ë¶€"]),
        ("ë°”ìš°ì € ì‹ ì²­", ["ë°”ìš°ì²˜", "ì‹ ì²­"]),
        ("ë°œì†¡ì†Œë¦¬ê°€ ë ê¹Œìš”", ["ë°œì†¡", "ì²˜ë¦¬"]),
        ("ì´ê¸¸ì˜ì—…ì¼ë‚ ", ["ìµì¼", "ì˜ì—…ì¼", "ë‚ "]),
    ]
    
    for text, expected_keywords in test_cases:
        print(f"\nì…ë ¥: {text}")
        
        # í˜•íƒœì†Œ ë¶„ì„
        morphemes = analyze_morphemes(text)
        print(f"í˜•íƒœì†Œ: {morphemes[:5]}...")
        
        # ëª…ì‚¬ ì¶”ì¶œ
        nouns = extract_nouns(text)
        print(f"ëª…ì‚¬: {nouns}")
        
        # ê²€ì¦
        success = all(keyword in nouns for keyword in expected_keywords)
        if success:
            print("âœ… êµì • ì„±ê³µ")
        else:
            print(f"âš ï¸ êµì • ì‹¤íŒ¨ - ê¸°ëŒ€ê°’: {expected_keywords}")
        
        print("-" * 70)


def test_pre_analyzed_words():
    """ê¸°ë¶„ì„ í˜•íƒœ ë“±ë¡ í…ŒìŠ¤íŠ¸"""
    print("\n" + "=" * 70)
    print("ê¸°ë¶„ì„ í˜•íƒœ ë“±ë¡ í…ŒìŠ¤íŠ¸")
    print("=" * 70)
    
    kiwi = get_kiwi()
    if kiwi is None:
        print("âŒ Kiwi ì´ˆê¸°í™” ì‹¤íŒ¨")
        return
    
    # ë“±ë¡ëœ íŒ¨í„´ í…ŒìŠ¤íŠ¸
    test_cases = [
        "í•˜ë‚˜ë‚¸",
        "ì—°ì˜ˆë¹„",
        "ë°”ìš°ì €",
        "ë°œì†¡ì†Œë¦¬ê°€",
        "ì´ê¸¸ì˜ì—…ì¼"
    ]
    
    for text in test_cases:
        print(f"\nì…ë ¥: {text}")
        tokens = kiwi.tokenize(text)
        print(f"ë¶„ì„ ê²°ê³¼: {[(t.form, t.tag) for t in tokens]}")
        print("-" * 70)


def test_integrated_pipeline():
    """í†µí•© íŒŒì´í”„ë¼ì¸ í…ŒìŠ¤íŠ¸"""
    print("\n" + "=" * 70)
    print("í†µí•© íŒŒì´í”„ë¼ì¸ í…ŒìŠ¤íŠ¸")
    print("=" * 70)
    
    test_cases = [
        "í•˜ë‚˜ë‚¸ ê³„ì¢Œì—ì„œ ë¨¼ì € ì¶œê¸ˆí• ê¹Œìš”",
        "ì—°ì˜ˆë¹„ ë‚©ë¶€ì™€ ê·¸ ë°”ìš°ì € í•œê°œ ì„ íƒ",
        "ì´ê¸¸ì˜ì—…ì¼ë‚  ë¬¸ìë¡œ ë°œì†¡ì†Œë¦¬ê°€ ë ê²ƒê°™ì•„ìš”",
        "ì ì‹œë§Œ ê¸°ë‹¤ë ¤ ì£¼ì‹œê² ìŠµë‹ˆê¹Œ",
    ]
    
    for text in test_cases:
        print(f"\nì…ë ¥: {text}")
        
        # í˜•íƒœì†Œ ë¶„ì„
        morphemes = analyze_morphemes(text)
        print(f"í˜•íƒœì†Œ ìˆ˜: {len(morphemes)}")
        
        # ëª…ì‚¬ ì¶”ì¶œ
        nouns = extract_nouns(text)
        print(f"ëª…ì‚¬: {nouns}")
        
        # ì£¼ìš” êµì • í™•ì¸
        corrections = []
        if "í•˜ë‚˜ì€í–‰" in nouns:
            corrections.append("í•˜ë‚˜ë‚¸ â†’ í•˜ë‚˜ì€í–‰")
        if "ì—°íšŒë¹„" in nouns:
            corrections.append("ì—°ì˜ˆë¹„ â†’ ì—°íšŒë¹„")
        if "ë°”ìš°ì²˜" in nouns:
            corrections.append("ë°”ìš°ì € â†’ ë°”ìš°ì²˜")
        if "ìµì¼" in nouns:
            corrections.append("ì´ê¸¸ â†’ ìµì¼")
        
        if corrections:
            print(f"êµì •: {', '.join(corrections)}")
            print("âœ… êµì • ì„±ê³µ")
        else:
            print("âš ï¸ êµì • ì—†ìŒ")
        
        print("-" * 70)


def main():
    """ë©”ì¸ í•¨ìˆ˜"""
    print("\nğŸš€ Kiwipiepy ê³ ê¸‰ ê¸°ëŠ¥ í…ŒìŠ¤íŠ¸ ì‹œì‘\n")
    
    # 1. ì˜¤íƒ€ êµì • í…ŒìŠ¤íŠ¸
    test_typo_correction()
    
    # 2. ê¸°ë¶„ì„ í˜•íƒœ í…ŒìŠ¤íŠ¸
    test_pre_analyzed_words()
    
    # 3. í†µí•© íŒŒì´í”„ë¼ì¸ í…ŒìŠ¤íŠ¸
    test_integrated_pipeline()
    
    print("\n" + "=" * 70)
    print("âœ… ëª¨ë“  í…ŒìŠ¤íŠ¸ ì™„ë£Œ")
    print("=" * 70)


if __name__ == "__main__":
    main()
