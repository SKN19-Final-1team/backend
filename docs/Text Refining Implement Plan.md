## 목표 기능

개선된 텍스트 교정

## 목적

기존 텍스트 교정 로직은 한국어 맞춤법 레벨의 교정만을 수행

테디카드 상품명 및 금융 용어와 같은 `명사`에 대한 교정 능력 부족

STT를 통해 전사된 `노이즈 섞인 텍스트`로부터, 발화자가 의도한 `정확한 카드상품명`을 복원하는 대응력 추가

**일반 사용자들은 정확한 상품명을 몰라 부정확하게 말할 수 있음**

## 개선 방안

1. DB에 정의된 테디카드 카드상품 리스트를 활용

2. STT를 통해 전사된 텍스트 입력

  - 개발 단계에서는 STT를 통해 받아졌다고 가정하고 일반 텍스트로 입력
  - 실제 운영에서는 STT를 통해 받아질 예정

3. 발음 유사성, 불필요한 띄어쓰기, 오탈자 등을 고려하여 정확한 테디카드 상품명으로 복원하여 후속 프로세스에 전달

  - 예시
    - "테니카드 서울 청년라이프" -> "테디카드 서울시 청년인생 설계학교"
    - "테디카드 청렴 주택 단보 대출" -> "테디카드 청년주택 담보대출"

## 고려사항

sLLM을 활용 vs 알고리즘 구현

어느 쪽이 더 나을지?

sLLM의 경우 `kanana-nano-2.1B-insturct` 모델을 활용할 예정

## 구현 방법

본 기능과 관련된 일체 모듈들은 `app/llm/delivery/` 안에 생성되며,

Runpod이 필요할 경우 `app/utils/runpod_connector.py` 활용

DB 연결은 `app/db/scripts/modules` 활용

- 단어사전은 DB 내 `keyword_dictionary` 테이블에서 `id`가 2484 이후의 행 이용

## 전체 흐름

1. STT 전사

사용자가 말한 날것 그대로의 데이터를 받아옵니다. STT가 인식하고 옮기는 과정에서 노이즈(맞춤법 및 띄어쓰기 오류, 발음 오류 등)가 섞일 수 있습니다.

2. 형태소 분석 (Targeting)

작업: morphology_analyzer.py를 실행합니다.

목적: **"교정할 대상을 좁히기 위해서"**입니다.

Why?: 문장 전체를 검색 엔진에 넣으면 정확도가 떨어집니다. "테니카드"라는 **명사(NNP)**만 쏙 뽑아서 검색해야 "테디카드"를 찾을 확률이 높아집니다.

입력: "테니카드로 결제해줘"

출력: ['테니카드(NNP)', '결제(NNG)']

3. 단어 매칭 및 교정 (Vocabulary Matching)

작업: vocabulary_matcher.py를 실행합니다.

목적: 추출된 명사("테니카드")가 우리 DB에 있는 "테디카드"인지 확인하고 바꿔치기합니다.

Why?: 형태소 분석기는 이게 오타인지 모릅니다. 매처(Matcher)가 DB와 대조해서 **"아, 이건 테디카드(유사도 0.92)구나"**라고 판별해줍니다.

4. 최종 문장 생성 및 저장 (Refining & Indexing)

작업: 교정된 단어들을 바탕으로 sLLM이 문맥과 문법 오류를 다듬고, 이를 후속 프로세스에서 활용 가능하도록 반환합니다.

목적: **"검색과 분석을 위해서"**입니다.

활용: 이후 RAG(검색 증강 생성)를 할 때는 이 교정된 텍스트를 검색하게 됩니다. 그래야 "테디카드"라고 검색했을 때 정확하게 걸리기 때문입니다.

5. 테스트

테스트 단계에서는 각 과정의 결과를 출력하여 디버깅이 가능하도록 합니다.